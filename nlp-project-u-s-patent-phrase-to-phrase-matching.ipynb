{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":33657,"databundleVersionId":3279164,"sourceType":"competition"}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-31T14:18:39.834748Z","iopub.execute_input":"2024-01-31T14:18:39.835483Z","iopub.status.idle":"2024-01-31T14:18:39.841984Z","shell.execute_reply.started":"2024-01-31T14:18:39.835448Z","shell.execute_reply":"2024-01-31T14:18:39.840830Z"},"trusted":true},"execution_count":253,"outputs":[{"name":"stdout","text":"/kaggle/input/us-patent-phrase-to-phrase-matching/sample_submission.csv\n/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv\n/kaggle/input/us-patent-phrase-to-phrase-matching/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Introduction \n\nThis project is based on the \"U.S. Patent Phrase to Phrase Matching\" competition that was hosted by Satsyil Corp in 2022. The idea is to compare two phrases, and score them based on whether they are similar or not. Determining the semantic similarity between phrases is crucial during the patent search and examination phase as it is used to detetermine if an invention is already documented. By recognizing equivalents like \"television set\" and \"TV set\" or broader matches such as \"strong material\" and \"steel,\" we can help patent attorneys and examiners in retrieving relevant documents. The goal of this NLP project is to develop a model that matches phrases in order to extract contextual information, to help the patent community connect the dots between millions of patent documents.","metadata":{}},{"cell_type":"markdown","source":"# Setup \nWe start by creating a boolean that tells us whether or not we are running on Kaggle. The dataset used is only available from Kaggle, so the easiest way to run this notebook is by running it on Kaggle. If you are running it on your own PC or GPU server you will need to download the dataset using the Kaggle API (not done in this notebook).","metadata":{}},{"cell_type":"code","source":"iskaggle = os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\", \"\")","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:39.844142Z","iopub.execute_input":"2024-01-31T14:18:39.844497Z","iopub.status.idle":"2024-01-31T14:18:39.854723Z","shell.execute_reply.started":"2024-01-31T14:18:39.844463Z","shell.execute_reply":"2024-01-31T14:18:39.853899Z"},"trusted":true},"execution_count":254,"outputs":[]},{"cell_type":"markdown","source":"We then create a path object that points to the directory containing our data and download the datasets library developed by Hugging Face, which is used to load and process datasets (we will be using the Transformers library in the Hugging Face ecosystem).","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\n\nif iskaggle:\n    path = Path('../input/us-patent-phrase-to-phrase-matching')\n    ! pip install -q datasets","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:39.855927Z","iopub.execute_input":"2024-01-31T14:18:39.856211Z","iopub.status.idle":"2024-01-31T14:18:52.129827Z","shell.execute_reply.started":"2024-01-31T14:18:39.856187Z","shell.execute_reply":"2024-01-31T14:18:52.128322Z"},"trusted":true},"execution_count":255,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let's check that we have our data:","metadata":{}},{"cell_type":"code","source":"!ls {path}","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:52.133673Z","iopub.execute_input":"2024-01-31T14:18:52.134095Z","iopub.status.idle":"2024-01-31T14:18:53.140665Z","shell.execute_reply.started":"2024-01-31T14:18:52.134059Z","shell.execute_reply":"2024-01-31T14:18:53.139480Z"},"trusted":true},"execution_count":256,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"sample_submission.csv  test.csv  train.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We will use the Pandas library for working with our csv files:","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:53.142121Z","iopub.execute_input":"2024-01-31T14:18:53.142542Z","iopub.status.idle":"2024-01-31T14:18:53.148689Z","shell.execute_reply.started":"2024-01-31T14:18:53.142504Z","shell.execute_reply":"2024-01-31T14:18:53.147692Z"},"trusted":true},"execution_count":257,"outputs":[]},{"cell_type":"markdown","source":"Let's set a path to our training data:","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(path/\"train.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:53.150105Z","iopub.execute_input":"2024-01-31T14:18:53.150527Z","iopub.status.idle":"2024-01-31T14:18:53.219477Z","shell.execute_reply.started":"2024-01-31T14:18:53.150493Z","shell.execute_reply":"2024-01-31T14:18:53.218689Z"},"trusted":true},"execution_count":258,"outputs":[]},{"cell_type":"markdown","source":"Let's take a look at our data:","metadata":{}},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:53.220520Z","iopub.execute_input":"2024-01-31T14:18:53.220786Z","iopub.status.idle":"2024-01-31T14:18:53.236124Z","shell.execute_reply.started":"2024-01-31T14:18:53.220762Z","shell.execute_reply":"2024-01-31T14:18:53.235293Z"},"trusted":true},"execution_count":259,"outputs":[{"execution_count":259,"output_type":"execute_result","data":{"text/plain":"                     id        anchor                  target context  score\n0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50\n1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75\n2      36d72442aefd8232     abatement         active catalyst     A47   0.25\n3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50\n4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00\n...                 ...           ...                     ...     ...    ...\n36468  8e1386cbefd7f245  wood article          wooden article     B44   1.00\n36469  42d9e032d1cd3242  wood article              wooden box     B44   0.50\n36470  208654ccb9e14fa3  wood article           wooden handle     B44   0.50\n36471  756ec035e694722b  wood article         wooden material     B44   0.75\n36472  8d135da0b55b8c88  wood article        wooden substrate     B44   0.50\n\n[36473 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>37d61fd2272659b1</td>\n      <td>abatement</td>\n      <td>abatement of pollution</td>\n      <td>A47</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7b9652b17b68b7a4</td>\n      <td>abatement</td>\n      <td>act of abating</td>\n      <td>A47</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36d72442aefd8232</td>\n      <td>abatement</td>\n      <td>active catalyst</td>\n      <td>A47</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5296b0c19e1ce60e</td>\n      <td>abatement</td>\n      <td>eliminating process</td>\n      <td>A47</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54c1e3b9184cb5b6</td>\n      <td>abatement</td>\n      <td>forest region</td>\n      <td>A47</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36468</th>\n      <td>8e1386cbefd7f245</td>\n      <td>wood article</td>\n      <td>wooden article</td>\n      <td>B44</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>36469</th>\n      <td>42d9e032d1cd3242</td>\n      <td>wood article</td>\n      <td>wooden box</td>\n      <td>B44</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>36470</th>\n      <td>208654ccb9e14fa3</td>\n      <td>wood article</td>\n      <td>wooden handle</td>\n      <td>B44</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>36471</th>\n      <td>756ec035e694722b</td>\n      <td>wood article</td>\n      <td>wooden material</td>\n      <td>B44</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>36472</th>\n      <td>8d135da0b55b8c88</td>\n      <td>wood article</td>\n      <td>wooden substrate</td>\n      <td>B44</td>\n      <td>0.50</td>\n    </tr>\n  </tbody>\n</table>\n<p>36473 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"And let's get some more information about this data to understand it better:","metadata":{}},{"cell_type":"code","source":"df.describe(include=\"object\")","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:53.237384Z","iopub.execute_input":"2024-01-31T14:18:53.237739Z","iopub.status.idle":"2024-01-31T14:18:53.322587Z","shell.execute_reply.started":"2024-01-31T14:18:53.237707Z","shell.execute_reply":"2024-01-31T14:18:53.321711Z"},"trusted":true},"execution_count":260,"outputs":[{"execution_count":260,"output_type":"execute_result","data":{"text/plain":"                      id                       anchor       target context\ncount              36473                        36473        36473   36473\nunique             36473                          733        29340     106\ntop     8d135da0b55b8c88  component composite coating  composition     H01\nfreq                   1                          152           24    2186","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>36473</td>\n      <td>36473</td>\n      <td>36473</td>\n      <td>36473</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>36473</td>\n      <td>733</td>\n      <td>29340</td>\n      <td>106</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>8d135da0b55b8c88</td>\n      <td>component composite coating</td>\n      <td>composition</td>\n      <td>H01</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>152</td>\n      <td>24</td>\n      <td>2186</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"This tells us that we have 733 unique anchors, almost 30000 unique targets and 106 contexts. We also see the \"component composite coating\" is a very common anchor as it appears 152. The goal of this project is to rate how similar an anchor and target phrase is in the range 0-1. A very close match receives the score 1.0, a close synonym (e.g. \"mobile phone vs. \"cellphone\") receives the score 0.75, synonyms which don't have the same meaning get the score 0.5, somewhat realted phrases (e.g. two phrases that are in the same high level domain but are not synonyms) get a score of 0.25, and unrelated phrases get a score of 0.0. These scores can be seen in the \"score\" column in the dataframe above. The similarity between phrases has been scores within a patent's context (specifically its CPC classification), which indicates the subject to which the patent relates. ","metadata":{}},{"cell_type":"markdown","source":"We will now create the input to our model. The values will be in the form \"TEXT1: context; TEXXT2: target; TEXT3: anchor\". ","metadata":{}},{"cell_type":"code","source":"df[\"input\"] = \"TEXT1: \" + df.context + \"; TEXT2: \" + df.target + \"; TEXT3: \" + df.anchor","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:53.323944Z","iopub.execute_input":"2024-01-31T14:18:53.324296Z","iopub.status.idle":"2024-01-31T14:18:53.352199Z","shell.execute_reply.started":"2024-01-31T14:18:53.324263Z","shell.execute_reply":"2024-01-31T14:18:53.351343Z"},"trusted":true},"execution_count":261,"outputs":[]},{"cell_type":"markdown","source":"Let's look at the first few rows:","metadata":{}},{"cell_type":"code","source":"df.input.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:53.355998Z","iopub.execute_input":"2024-01-31T14:18:53.356811Z","iopub.status.idle":"2024-01-31T14:18:53.366579Z","shell.execute_reply.started":"2024-01-31T14:18:53.356783Z","shell.execute_reply":"2024-01-31T14:18:53.365685Z"},"trusted":true},"execution_count":262,"outputs":[{"execution_count":262,"output_type":"execute_result","data":{"text/plain":"0    TEXT1: A47; TEXT2: abatement of pollution; TEX...\n1    TEXT1: A47; TEXT2: act of abating; TEXT3: abat...\n2    TEXT1: A47; TEXT2: active catalyst; TEXT3: aba...\n3    TEXT1: A47; TEXT2: eliminating process; TEXT3:...\n4    TEXT1: A47; TEXT2: forest region; TEXT3: abate...\nName: input, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# Tokenization\n\nTranformers uses a Dataset object to store datasets, so we will store our dataset in this object.","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict\n\nds = Dataset.from_pandas(df)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:53.367728Z","iopub.execute_input":"2024-01-31T14:18:53.368484Z","iopub.status.idle":"2024-01-31T14:18:53.399352Z","shell.execute_reply.started":"2024-01-31T14:18:53.368458Z","shell.execute_reply":"2024-01-31T14:18:53.398470Z"},"trusted":true},"execution_count":263,"outputs":[]},{"cell_type":"markdown","source":"Let's take a look at it:","metadata":{}},{"cell_type":"code","source":"ds","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:53.402552Z","iopub.execute_input":"2024-01-31T14:18:53.402866Z","iopub.status.idle":"2024-01-31T14:18:53.408636Z","shell.execute_reply.started":"2024-01-31T14:18:53.402840Z","shell.execute_reply":"2024-01-31T14:18:53.407752Z"},"trusted":true},"execution_count":264,"outputs":[{"execution_count":264,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'anchor', 'target', 'context', 'score', 'input'],\n    num_rows: 36473\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"We will now split each text up into tokens and convert each token into a number (as the model expects numbers as inputs). We will use the following model:","metadata":{}},{"cell_type":"code","source":"model_db = \"microsoft/deberta-v3-small\"","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:53.409925Z","iopub.execute_input":"2024-01-31T14:18:53.410491Z","iopub.status.idle":"2024-01-31T14:18:53.417035Z","shell.execute_reply.started":"2024-01-31T14:18:53.410459Z","shell.execute_reply":"2024-01-31T14:18:53.416250Z"},"trusted":true},"execution_count":265,"outputs":[]},{"cell_type":"markdown","source":"And we will use AutoTokenizer to create a tokenizer that is appropriate for our model:","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(model_db)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:53.418179Z","iopub.execute_input":"2024-01-31T14:18:53.418439Z","iopub.status.idle":"2024-01-31T14:18:54.650786Z","shell.execute_reply.started":"2024-01-31T14:18:53.418417Z","shell.execute_reply":"2024-01-31T14:18:54.649808Z"},"trusted":true},"execution_count":266,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:515: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let's see an example of how our tokenizer splits a text into tokens:","metadata":{}},{"cell_type":"code","source":"tokenizer.tokenize(\"TEXT1: A47; TEXT2: abatement of pollution; TEXT3: abatement\")","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:54.652278Z","iopub.execute_input":"2024-01-31T14:18:54.652622Z","iopub.status.idle":"2024-01-31T14:18:54.659292Z","shell.execute_reply.started":"2024-01-31T14:18:54.652590Z","shell.execute_reply":"2024-01-31T14:18:54.658430Z"},"trusted":true},"execution_count":267,"outputs":[{"execution_count":267,"output_type":"execute_result","data":{"text/plain":"['▁TEXT',\n '1',\n ':',\n '▁A',\n '47',\n ';',\n '▁TEXT',\n '2',\n ':',\n '▁abatement',\n '▁of',\n '▁pollution',\n ';',\n '▁TEXT',\n '3',\n ':',\n '▁abatement']"},"metadata":{}}]},{"cell_type":"markdown","source":"We now create a function that tokenizes our inputs and make sure we do this in parallel on every row in our dataset using map (this is a functional programming approach which means we apply a function to each element in the dataset, and setting batched = True means the map function will process the dataset in batches which is more efficient since our dataset is large):","metadata":{}},{"cell_type":"code","source":"def tokenize_input(x):\n    return tokenizer(x[\"input\"])\n\ntokenized_dataset = ds.map(tokenize_input, batched = True)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:54.660532Z","iopub.execute_input":"2024-01-31T14:18:54.660910Z","iopub.status.idle":"2024-01-31T14:18:57.172184Z","shell.execute_reply.started":"2024-01-31T14:18:54.660884Z","shell.execute_reply":"2024-01-31T14:18:57.171235Z"},"trusted":true},"execution_count":268,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/37 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4169b893853b4174b11de75cc20c2a1e"}},"metadata":{}}]},{"cell_type":"markdown","source":"Let's inspect the first row of our data:","metadata":{}},{"cell_type":"code","source":"first_row = tokenized_dataset[0]\nfirst_row[\"input\"], first_row[\"input_ids\"]","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:57.173337Z","iopub.execute_input":"2024-01-31T14:18:57.173659Z","iopub.status.idle":"2024-01-31T14:18:57.181416Z","shell.execute_reply.started":"2024-01-31T14:18:57.173617Z","shell.execute_reply":"2024-01-31T14:18:57.180478Z"},"trusted":true},"execution_count":269,"outputs":[{"execution_count":269,"output_type":"execute_result","data":{"text/plain":"('TEXT1: A47; TEXT2: abatement of pollution; TEXT3: abatement',\n [1,\n  54453,\n  435,\n  294,\n  336,\n  5753,\n  346,\n  54453,\n  445,\n  294,\n  47284,\n  265,\n  6435,\n  346,\n  54453,\n  508,\n  294,\n  47284,\n  2])"},"metadata":{}}]},{"cell_type":"markdown","source":"We can see the input and the IDs for the first row of our data. The tokenizer has a list called vocab which contains a unique integer for every possible token string, which gives us the ID for that token string. We can, for instance, look at the token for the string \"▁TEXT\":","metadata":{}},{"cell_type":"code","source":"tokenizer.vocab[\"▁TEXT\"]","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:57.183021Z","iopub.execute_input":"2024-01-31T14:18:57.183362Z","iopub.status.idle":"2024-01-31T14:18:57.288283Z","shell.execute_reply.started":"2024-01-31T14:18:57.183327Z","shell.execute_reply":"2024-01-31T14:18:57.287249Z"},"trusted":true},"execution_count":270,"outputs":[{"execution_count":270,"output_type":"execute_result","data":{"text/plain":"54453"},"metadata":{}}]},{"cell_type":"markdown","source":"As expected, the integer 54453 appears in the input IDs above. Lastly, Transformers expects our labels to have the column name \"labels\" so we have to rename it from \"score\" to \"labels\".","metadata":{}},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.rename_columns({\"score\": \"labels\"})","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:57.289829Z","iopub.execute_input":"2024-01-31T14:18:57.290508Z","iopub.status.idle":"2024-01-31T14:18:57.300781Z","shell.execute_reply.started":"2024-01-31T14:18:57.290468Z","shell.execute_reply":"2024-01-31T14:18:57.299801Z"},"trusted":true},"execution_count":271,"outputs":[]},{"cell_type":"markdown","source":"# Validation set\n\nWe can now create our validation set. We already have our test set:","metadata":{}},{"cell_type":"code","source":"test_set_df = pd.read_csv(path/\"test.csv\")\ntest_set_df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:57.302063Z","iopub.execute_input":"2024-01-31T14:18:57.302590Z","iopub.status.idle":"2024-01-31T14:18:57.324615Z","shell.execute_reply.started":"2024-01-31T14:18:57.302552Z","shell.execute_reply":"2024-01-31T14:18:57.323798Z"},"trusted":true},"execution_count":272,"outputs":[{"execution_count":272,"output_type":"execute_result","data":{"text/plain":"                      id          anchor                         target  \\\ncount                 36              36                             36   \nunique                36              34                             36   \ntop     4112d61851461f60  hybrid bearing  inorganic photoconductor drum   \nfreq                   1               2                              1   \n\n       context  \ncount       36  \nunique      29  \ntop        G02  \nfreq         3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>36</td>\n      <td>34</td>\n      <td>36</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>4112d61851461f60</td>\n      <td>hybrid bearing</td>\n      <td>inorganic photoconductor drum</td>\n      <td>G02</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We will use DatasetDict to split our tokenized dataset so that we 75% for training and 25% for validation:","metadata":{}},{"cell_type":"code","source":"dataset_dict = tokenized_dataset.train_test_split(0.25, seed = 42)\ndataset_dict","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:57.325736Z","iopub.execute_input":"2024-01-31T14:18:57.326032Z","iopub.status.idle":"2024-01-31T14:18:57.351350Z","shell.execute_reply.started":"2024-01-31T14:18:57.326005Z","shell.execute_reply":"2024-01-31T14:18:57.350535Z"},"trusted":true},"execution_count":273,"outputs":[{"execution_count":273,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 27354\n    })\n    test: Dataset({\n        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 9119\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"This uses a random split to split the dataset into a training and validation set (NB: the validation set is called test in the DatasetDict, but it is our validation set). We will train our model on our training set and use the validation set to make it more accurate. Once our entire training process is done we will test our model on our test set. (The reason we need a test set is that while training the model we might find things that coincidentally improve our validation set metrics, without the model actually becoming better in practice; in other words we are over-fitting on our validation set.)\n\nTo avoid confusion with the test dataset that was created above we will call our actual test set \"final_test_dataset\":","metadata":{}},{"cell_type":"code","source":"test_set_df[\"input\"] = \"TEXT1: \" + test_set_df.context + \"; TEXT2: \" + test_set_df.target + \"; TEXT3: \" + test_set_df.anchor\nfinal_test_dataset = Dataset.from_pandas(test_set_df).map(tokenize_input, batched = True)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:18:57.352383Z","iopub.execute_input":"2024-01-31T14:18:57.352669Z","iopub.status.idle":"2024-01-31T14:18:57.391042Z","shell.execute_reply.started":"2024-01-31T14:18:57.352622Z","shell.execute_reply":"2024-01-31T14:18:57.390165Z"},"trusted":true},"execution_count":274,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1226912096ab4a4299cb3e2d2ab45971"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Training our model\n\nSubmissions for this problem are evaluated on the Pearson correlation coefficient between predicted and actual similarity scores. Transformers expects metrics to be returned as a dictionary since that's how the trainer knows what label to use, so we will create functions to do that:","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef corr(x,y): \n    return np.corrcoef(x,y)[0][1]\n\ndef corr_d(eval_pred):\n    return {\"pearson\": corr(*eval_pred)}","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:28:10.703525Z","iopub.execute_input":"2024-01-31T14:28:10.704486Z","iopub.status.idle":"2024-01-31T14:28:10.709533Z","shell.execute_reply.started":"2024-01-31T14:28:10.704450Z","shell.execute_reply":"2024-01-31T14:28:10.708586Z"},"trusted":true},"execution_count":280,"outputs":[]},{"cell_type":"markdown","source":"We will now import what we need to train our model, We also set the batch size to 128, train for 4 epochs and set the learning rate to 8e-5:","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\nbatch_size = 128\nepochs = 4\nlr = 8e-5","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:28:14.324087Z","iopub.execute_input":"2024-01-31T14:28:14.324792Z","iopub.status.idle":"2024-01-31T14:28:14.329402Z","shell.execute_reply.started":"2024-01-31T14:28:14.324753Z","shell.execute_reply":"2024-01-31T14:28:14.328438Z"},"trusted":true},"execution_count":281,"outputs":[]},{"cell_type":"markdown","source":"We use TrainingArguments to set up the arguments: ","metadata":{}},{"cell_type":"code","source":"args = TrainingArguments('outputs', learning_rate = lr, warmup_ratio = 0.1, lr_scheduler_type = 'cosine', fp16 = True,\n    evaluation_strategy = \"epoch\", per_device_train_batch_size = batch_size, per_device_eval_batch_size = batch_size * 2,\n    num_train_epochs = epochs, weight_decay = 0.01, report_to = 'none')","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:28:18.030217Z","iopub.execute_input":"2024-01-31T14:28:18.030866Z","iopub.status.idle":"2024-01-31T14:28:18.036152Z","shell.execute_reply.started":"2024-01-31T14:28:18.030829Z","shell.execute_reply":"2024-01-31T14:28:18.035275Z"},"trusted":true},"execution_count":282,"outputs":[]},{"cell_type":"markdown","source":"We can now create our model and trainer:","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(model_db, num_labels = 1)\ntrainer = Trainer(model, args, train_dataset = dataset_dict['train'], eval_dataset = dataset_dict['test'],\n                  tokenizer = tokenizer, compute_metrics = corr_d)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:28:23.469442Z","iopub.execute_input":"2024-01-31T14:28:23.469830Z","iopub.status.idle":"2024-01-31T14:28:23.990862Z","shell.execute_reply.started":"2024-01-31T14:28:23.469799Z","shell.execute_reply":"2024-01-31T14:28:23.990063Z"},"trusted":true},"execution_count":283,"outputs":[{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"(Transformers spits out a lot of warnings but we can ignore them.) Time to train our model:","metadata":{}},{"cell_type":"code","source":"trainer.train();","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:28:27.985938Z","iopub.execute_input":"2024-01-31T14:28:27.986401Z","iopub.status.idle":"2024-01-31T14:33:17.281917Z","shell.execute_reply.started":"2024-01-31T14:28:27.986363Z","shell.execute_reply":"2024-01-31T14:33:17.281038Z"},"trusted":true},"execution_count":284,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='428' max='428' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [428/428 04:47, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Pearson</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.027985</td>\n      <td>0.778681</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.026020</td>\n      <td>0.810518</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.025371</td>\n      <td>0.821559</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.024339</td>\n      <td>0.823245</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"markdown","source":"Recall that the submissions for this problem are evaluated on the Pearson correlation coefficient between predicted and actual similarity scores. As we can see, the Pearson correlation increases in each training cycle and is above 0.8. \n\nAs a final step, we can get some predictions on the test set:","metadata":{}},{"cell_type":"code","source":"preds = trainer.predict(final_test_dataset).predictions.astype(float)\npreds","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:44:46.207521Z","iopub.execute_input":"2024-01-31T14:44:46.208299Z","iopub.status.idle":"2024-01-31T14:44:46.343113Z","shell.execute_reply.started":"2024-01-31T14:44:46.208265Z","shell.execute_reply":"2024-01-31T14:44:46.342143Z"},"trusted":true},"execution_count":285,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":285,"output_type":"execute_result","data":{"text/plain":"array([[ 0.5629527 ],\n       [ 0.70889294],\n       [ 0.55079079],\n       [ 0.40113348],\n       [-0.00786009],\n       [ 0.5348739 ],\n       [ 0.49597657],\n       [ 0.01237161],\n       [ 0.23974185],\n       [ 1.09340847],\n       [ 0.25360519],\n       [ 0.21818624],\n       [ 0.74570519],\n       [ 0.95155936],\n       [ 0.77776659],\n       [ 0.37234166],\n       [ 0.26105428],\n       [-0.03651068],\n       [ 0.64209932],\n       [ 0.33149865],\n       [ 0.35574993],\n       [ 0.25540748],\n       [ 0.00154419],\n       [ 0.23447916],\n       [ 0.58790159],\n       [-0.02431577],\n       [-0.02842573],\n       [ 0.00317116],\n       [-0.03988128],\n       [ 0.62946129],\n       [ 0.35683072],\n       [ 0.06851827],\n       [ 0.69592309],\n       [ 0.49425533],\n       [ 0.48538256],\n       [ 0.19975954]])"},"metadata":{}}]},{"cell_type":"markdown","source":"Since some of our correlations are below 0 and above 1 we will fix those out-of-bound predictions:","metadata":{}},{"cell_type":"code","source":"preds = np.clip(preds, 0, 1)\npreds","metadata":{"execution":{"iopub.status.busy":"2024-01-31T14:46:02.557133Z","iopub.execute_input":"2024-01-31T14:46:02.557515Z","iopub.status.idle":"2024-01-31T14:46:02.565639Z","shell.execute_reply.started":"2024-01-31T14:46:02.557484Z","shell.execute_reply":"2024-01-31T14:46:02.564522Z"},"trusted":true},"execution_count":286,"outputs":[{"execution_count":286,"output_type":"execute_result","data":{"text/plain":"array([[0.5629527 ],\n       [0.70889294],\n       [0.55079079],\n       [0.40113348],\n       [0.        ],\n       [0.5348739 ],\n       [0.49597657],\n       [0.01237161],\n       [0.23974185],\n       [1.        ],\n       [0.25360519],\n       [0.21818624],\n       [0.74570519],\n       [0.95155936],\n       [0.77776659],\n       [0.37234166],\n       [0.26105428],\n       [0.        ],\n       [0.64209932],\n       [0.33149865],\n       [0.35574993],\n       [0.25540748],\n       [0.00154419],\n       [0.23447916],\n       [0.58790159],\n       [0.        ],\n       [0.        ],\n       [0.00317116],\n       [0.        ],\n       [0.62946129],\n       [0.35683072],\n       [0.06851827],\n       [0.69592309],\n       [0.49425533],\n       [0.48538256],\n       [0.19975954]])"},"metadata":{}}]},{"cell_type":"markdown","source":"Since the competition is over and there are a lot of steps needed to submit to Kaggle now that it's over I won't submit this solution to Kaggle. But to summarize: we see a Pearson correlation that is above 0.8 on the validation set, and we can also get some predictions on the test set.","metadata":{}}]}